\documentclass[compress,mathserif,xcolor=dvipsnames,svgnames,aspectratio=43]{beamer}
%% $%!TEX program = xelatex
\usetheme{Algiers}

%%% My favorite packages

%\usepackage[default]{sourcesanspro}
% \usepackage[default]{raleway}

%\usepackage[T1]{fontenc}
%\usefonttheme[onlymath]{serif}

% \usepackage{fontspec}
% \usepackage{xunicode} %Unicode extras!
% \usepackage{xltxtra}  %Fixes
% \usepackage{Ubuntu}
% \usepackage[final,expansion=true,protrusion=true,spacing=true,kerning=true]{microtype} % better font output

%%% Really nice for tables
% \usepackage{booktabs}
% \newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}
% \usepackage{float}

%%% Citations
% \usepackage{natbib}
% \renewcommand{\bibsection}{\subsubsection*{\bibname } } %prevents natbib from adding a section
\usepackage[english]{babel}
% \usepackage[utf8]{inputenc}
\usepackage{multirow}

% It puts a simplistic plain slide with the section name
% at the beginning of each section
\usepackage{nameref}
\makeatletter
\newcommand*{\currentname}{\@currentlabelname}
\makeatother
\AtBeginSection[]
{
\plaintitle{\currentname}
}

% Take this off when using the template
\usepackage{blindtext}
\usepackage{graphicx}

\setbeamertemplate{bibliography item}{\insertbiblabel}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\title{\huge{Current Progress in \\ Emergent Numerals Project}\\\medskip
    \large\textcolor{beautyblue}{} \medskip}
\author{\textcolor{grizoo}{Shangmin (Shawn) Guo}}
\date[someday\ldots]{\today}%{1\up{er} juillet 2010}
\institute{School of Informatics, The University of Edinburgh}

\begin{frame}[plain, noframenumbering]
\titlepage
\end{frame}

%% the content page
\begin{frame}[plain, noframenumbering]
\frametitle{Content}
\tableofcontents
\end{frame}

%% the first section
\section{Task Description \& Models}

\begin{frame}[c]
  \frametitle{Task}
  \begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{graph/task.pdf}
    \caption{set-to-set task}
    \label{fig:1task}
  \end{figure}
  \begin{block}{Numerals}
    Symbols used to represent numbers of objects in a set.
  \end{block}
\end{frame}

\begin{frame}[c]
  \frametitle{Non-communication Models}
  \begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{graph/set_seq-2-seq.pdf}
    \caption{set/seq-to-seq models}
    \label{fig:2set_seq2seq}
  \end{figure}
  \begin{itemize}
    \item seq2seq: just as normal
    \item set2seq: attention times equal to numbers of types of objects
  \end{itemize}
\end{frame}

\begin{frame}[c]
  \frametitle{Communication Models}
  \begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{graph/set2seq2seq_model.pdf}
    \caption{set-to-seq-to-seq model}
    \label{fig:3set2seq2seq_model}
  \end{figure}
  \vspace{-0.25in}
  \begin{itemize}
    \item at this moment, we fix the order of output symbols
    \item messages can have variable lengths
    \item sampling methods during training: 
      \begin{itemize}
        \item GUMBEL-softmax trick
        \item REINFORCE (+SCST)
      \end{itemize}
  \end{itemize}
\end{frame}

%=============================================================================================%
\section{Experiments Results \& Preliminary Discussion}

\begin{frame}[c]
  \frametitle{Model Performances}
  \begin{itemize}
    \item Non-communication models
      \begin{itemize}
        \item seq2seq: 100\% seq acc, 100\% tok acc, 0.0000 on loss 
        \item set2seq: 100\% seq acc, 100\% tok acc, 0.0000 on loss
      \end{itemize}
    \item Set2seq2seq (discrete symbols)
      \begin{itemize}
        \item Straight-Through GUMBEL-softmax: 99.89\% seq acc, 99.99\% tok acc, 0.0001 on loss
        \item REINFORCE: 89.89\% seq acc, 93.67\% tok acc, 0.0006 on loss
        \item REINFORCE+SCST: 98.67\% seq acc, 99.64\% tok acc, 0.0002 on loss
      \end{itemize}
  \end{itemize}

  \begin{block}{Uniqueness of Numerals}
    A single symbol in \textcolor{red}{different} postions represent \textcolor{red}{same} meaning.
  \end{block}
\end{frame}

\begin{frame}[c]
  \frametitle{Visualisation of Messages (1)}
  \begin{columns}
    \column{0.33\textwidth}
    \includegraphics[width=0.9\textwidth]{graph/DABC.png} \\
    \includegraphics[width=0.9\textwidth]{graph/DACB.png}
    \column{0.33\textwidth}
    \includegraphics[width=0.9\textwidth]{graph/DBAC.png} \\
    \includegraphics[width=0.9\textwidth]{graph/DBCA.png}
    \column{0.33\textwidth}
    \includegraphics[width=\textwidth]{graph/DCAB.png} \\
    \includegraphics[width=\textwidth]{graph/DCBA.png}
  \end{columns}
\end{frame}

\begin{frame}[c]
  \frametitle{Visualisation of Messages (2)}
  \includegraphics[width=0.9\textwidth]{graph/DCAB.png}
\end{frame}

\begin{frame}[c]
  \frametitle{Topological Similarity in \cite{brighton2006understanding}}
  \begin{block}{General definition}
    Correlation between \textcolor{red}{hamming} distances in meaning space and \textcolor{red}{edit} distances in signal space.
  \end{block}
  \begin{itemize}
    \item natural language
      \begin{itemize}
        \item e.g. `ABCCD' -> `1121'
        \item pearson: 0.9434, spearman: 0.9316
        \item why not 1: (`1A2B3C4D', `1234') vs (`4A1B2C3D', `4123')
        \item use hamming distance in symbol space: pearson 1.0, 
        \item (more on next page)
      \end{itemize}
    \item emergent protocol:
    \begin{itemize}
      \item e.g. `ABCCD' -> `33213112'
      \item pearson: , spearman: 
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[c]
  \frametitle{Limitation of Topological Similarity}
  Base meaning: `1A2B3C4D'
  
  \begin{itemize}
    \item `1A2B3C\textcolor{red}{5}D' v.s. `1A2B\textcolor{red}{4}C4D': $\mathcal{D}_m$ are both $1$, $\mathcal{D}_s$ are both $1$; brilliant!
    \item `1A2B3C\textcolor{red}{5}D' v.s. `1A2B\textcolor{red}{4}C\textcolor{red}{5}D': $\mathcal{D}_m$ are $1:2$, $\mathcal{D}_s$ are $1:2$; \\still brilliant!
    \pause
    \item `1A2B3C\textcolor{red}{5}D' v.s. `1A2B3C\textcolor{red}{7}D': $\mathcal{D}_m$ are both $1$, $\mathcal{D}_s$ are both $1$;
  \end{itemize}

  \pause
  \begin{block}{Question}
    `1A2B3C\textcolor{red}{5}D' and `1A2B3C\textcolor{red}{7}D' share same $\mathcal{D}_m$?
  \end{block}

\end{frame}

\begin{frame}[c]
  \frametitle{Back to Original Form?}
  Base meaning: `1A2B3C4D' -> `ABBCCCDDDD' \\
  Then, hamming distances -> edit distances in meaning space.
  \begin{itemize}
    \item natural language
      \begin{itemize}
        \item e.g. `ABCCD' -> `1121'
        \item pearson: 0.4375, spearman: 0.4198
      \end{itemize}
    \item emergent protocol:
    \begin{itemize}
      \item e.g. `ABCCD' -> `33213112'
      \item pearson: , spearman:
    \end{itemize}
  \end{itemize}

  \begin{block}{Problem}
    `1A2B3C4D' vs `1A2B3C\textcolor{red}{9}D': $\mathcal{D}_m = 5$ vs $\mathcal{D}_s = 1$
  \end{block}
\end{frame}

\begin{frame}[c]
  \frametitle{Expected Properties of Measurements}
  \begin{enumerate}
    \item \textbf{Orthogonality \& Mutual Exclusivity}:
            \begin{itemize}
              \item symbols describing different attributes/objects should be orthogonal to each other
              \item symbols describing a same attribute of a same object should be mutually exclusive to each other
            \end{itemize}
    \item \textbf{Monotony \& Topological Similarity}:
            \begin{itemize}
              \item closer in meaning space -> closer in symbol space 
              \item $\approx$ similar topological structure between 2 spaces
              \item intuitions from 2D space seem correct, what about in high-dimensional space?
            \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}[c]
  \frametitle{Tentative Explaination of Limiting $|V|$ and $L$ (1)}
  Meaning space:
  \begin{itemize}
    \item \# of attributes is $N$, range of attributes is $|A|$
    \item size of meaning space is $|\mathcal{M}| = |A|^N$
    \item e.g. color (red R + green G) and shape (square S + circle C)
  \end{itemize}

  Symbol space:
  \begin{itemize}
    \item length of message is $L$, size of vocabulary is $|V|$
    \item size of symbol space is $|\mathcal{S}| = |V|^L$ (fixed lengths)
    \item e.g. \{aa, ab, ba, bb\}
  \end{itemize}
  Total number of ``languages'': $|\mathcal{S}|^{|\mathcal{M}|} = {(|V|^L)}^{(|A|^N)}$, e.g. $4^4=256$ \\
  \# of degenerate languages: $|\mathcal{S}| = |V|^L$, e.g. $4$
\end{frame}

\begin{frame}[c]
  \frametitle{Tentative Explaination of Limiting $|V|$ and $L$ (2)}
  \begin{itemize}
    \item \# of holistic+compositional languages: $\frac{|\mathcal{S}|!}{(|\mathcal{S}|-|\mathcal{M}|)!} = \frac{|V|^L !}{(|V|^L - |A|^N)!}$, e.g. $\frac{4!}{(4-4)!}=24$
    \item Context-free-grammar and number of compositional languages:
      \begin{enumerate}
        \item $S\rightarrow A_1\ A_2\dots A_N$: $N!$, e.g. $2$
        \item $A_i\rightarrow V_k$: $(|V|\cdot (|V|-1)\dots)^N = \left(\frac{|V|!}{(|V|-|A|)!}\right)^N$, $2^2 = 4$
        \item \# of compositional languages: $N!\cdot \left(\frac{|V|!}{(|V|-|A|)!}\right)^N$, e.g. $2\cdot 4=8$
      \end{enumerate}
    \item \# of holistic languages: $\frac{|V|^L !}{(|V|^L - |A|^N)!} - N!\cdot \left(\frac{|V|!}{(|V|-|A|)!}\right)^N$, e.g. $24-8=16$
  \end{itemize}
\end{frame}

\begin{frame}[c]
  \frametitle{Tentative Explaination of Limiting $|V|$ and $L$ (3)}
  $|V|=|A|=L=N$ and $2$ in \cite{li2019ease}.
  \begin{columns}
    \column{0.25\textwidth}
    \includegraphics[width=\textwidth]{graph/size_left.png}
    \column{0.5\textwidth}
    \includegraphics[width=\textwidth]{graph/size_mid.png}
  \end{columns}
  N.B. both of above graphs are in log-space.
\end{frame}

\begin{frame}[c]
  \frametitle{Tentative Explaination of Limiting $|V|$ and $L$ (4)}
  $|A|=L=N=2, V$ is a variable \\
  \begin{center}
    \includegraphics[width=0.5\textwidth]{graph/size_V.png}
  \end{center}
\end{frame}

\begin{frame}[c]
  \frametitle{Fraction of Compositional Languages in Our Project}
  \begin{itemize}
    \item \# of compositional languages: \\ $N!\cdot \left(\frac{|V|!}{(|V|-|A|)!}\right)^N = 4!\cdot \left(\frac{10!}{(10-10)!}\right)^4 \approx 4.16\times 10^{28}$
    \pause
    \item \# of holistic+compositional: $\frac{|V|^L !}{(|V|^L - |A|^N)!} = \frac{10^9!}{(10^9-10^4)!} \approx 9.51\times 10^{8999}$
    \item farction is $\frac{1}{4.27\times 10^{8970}}$
    \pause
    \item \# of atoms on Earth $\approx 1.33\times 10^{50}$
  \end{itemize}
\end{frame}


%=============================================================================================%
\section{Next Steps}

\begin{frame}[c]
  \frametitle{Next Steps}
  \begin{enumerate}
    \item decrease $|\mathcal{M}|$ and $|\mathcal{S}|$
    \item find a new measurement/technique that could satisfy the expected properties, e.g. Discrete Component Analysis
    \item population and ease-of-teaching
  \end{enumerate}
  
\end{frame}


% A trick for having back slides while ending the slide counter
% on the conclusion slide
\appendix
\newcounter{finalframe}
\setcounter{finalframe}{\value{framenumber}}

% Geeky ending
\begin{frame}[c,plain,fragile] %fragile
%\begin{python}
%feedback = raw_input( 'Questions ?' )
%if '?' in feedback:
%    if have_answer():
%        give_answer()
%    else:
%        pretend_the_question_is_ill_posed()
%else:
%    print 'Thanks, let us go get MIX now.'
%\end{python}

% Or simply...
\begin{center}
\huge{Thank you}
\end{center}
\end{frame}

% References
\begin{frame}[allowframebreaks, plain]
\tiny{
   \bibliographystyle{apalike}
   \bibliography{slides}
}
\end{frame}

\setcounter{framenumber}{\value{finalframe}}
\end{document}
