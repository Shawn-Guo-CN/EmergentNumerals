\chapter{Experiment Results and Discussion}
\label{ch4:results_analysis}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Emergence of Language without Iterated Learning}
\label{sec4.1:emergence}

First of all, we have to verify that the agents can successfully address the problems by communicating with discrete symbols. After tried several different settings, to avoid that the success of agents depends on fine-tuning hyperparameters, we find that it is better to make the size of message space much larger than the size of meaning space. Thus, we set the size of message space $|V|^{|M|}$ to be 100 times of the meaning space $|N_{o}|^{|\mathcal{O}|}$ and show the performance of both ``Set2Seq2Seq'' and ``Set2Seq2Choice'' in Table \ref{tab4.1:game_performance}. In the table, $|M|$ is the length of messages, $|V|$ is the size of vocabulary\footnote{Note that the meaning of ``vocabulary" is not like it is in traditional NLP, but refers to the set of initially meaningless symbols that can be used for communication.} for message, $|\mathcal{O}|$ is the number of all kinds of objects and $|N_o|$ is the maximum number of a single kind of object.

Additionally, as the training procedure is time-consuming, all the shown performance are based on a single run, and thus the effects from hyperparameters and randomness cannot be completely filtered out. However, as we did not intentionally fine-tune the hyperparameters and we focus on the emergent communication protocols, we believe that the variabilities of performance is limited and would not affect our following discussions. 

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Model                           & Sampling Method & Performance & Game Setting      \\ \hline
        \multirow{3}{*}{Set2Seq2Seq}    & GUMBEL          & 99.89\%     & \multirow{3}{1.5in}{$|M|=8$, $|V|=10$, $|\mathcal{O}|=6$, $|N_{o}|=10$} \\ \cline{2-3}
                                        & REINFORCE       & 89.89\%     &                   \\ \cline{2-3}
                                        & SCST            & 98.67\%     &                   \\ \hline
        \multirow{3}{*}{Set2Seq2Choice} & GUMBEL          & 100\%       & \multirow{3}{1.5in}{$|M|=6$, $|V|=10$, $|\mathcal{O}|=4$, $|N_{o}|=10$} \\ \cline{2-3}
                                        & REINFORCE       & 76.45\%     &                   \\ \cline{2-3}
                                        & SCST            & 83.26\%     &                   \\ \hline
        \end{tabular}
    \caption{Performance of Models and Corresponding Game Settings.}
    \label{tab4.1:game_performance}
\end{table}

Besides the ``REINFORCE'' and ``GUMBEL'' sampling methods introduced in subsection \ref{sssec3.2.1.2:msg_generator}, we also tried the self-critic sequence training proposed by \cite{rennie2017self} as a baseline for REINFORCE algorithm, which is denoted by ``SCST''. Briefly speaking, SCST utilises the output of its own test-time inference algorithm to normalize the rewards received instead of estimating a separate “baseline”.

Based on the performance shown in Table \ref{tab4.1:game_performance}, it is clear that GUMBEL is the most stable sampling method on all different settings. Thus, unless specifically stated, the following experiments and discussions are all based on training agents with GUMBEL-softmax as message sampling method.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Structure of Emergent Language}
\label{sec4.2:structure_emergent_lan}

\subsection{Emergent Languages in Various Games}
\label{ssec4.2.1:emergent_languages}

After verifying that computational agents are able to complete games through communication, we are curious about the messages produced during their communication. However, unlike what was shown by the previous works in GLL, e.g. \cite{hill2017understanding} and \cite{mordatch2018emergence}, the emergent language during both Set-Reconstruct and Set-Select games are not ``perfectly'' compositional, which will be illustrated later. From our perspective, one alternative explanation for this phenomenon is that $|M| > |\mathcal{O}|$ in our game settings, which makes proportion of holistic languages \footnote{A holistic language is a language that needs to be learned as a whole and should not be analysed or compartmentalized.} much larger than the proportion of compositional languages \cite{brighton2002compositional}, and thus it becomes very hard to find compositional languages.

To have give an intuitive demonstration of the emergent language, we list all messages transmitted in a Set-Reconstruct game where $|\mathcal{O}|=2, |N_o|=5, |M|=4, |V|=10$ in Table \ref{tab4.2:emregent_language_generation} given as follow. In the table, the first row and first column are the basic elements of meanings and each cell is the corresponding message for that meaning. Take cell ``1A2B'' for example, the original input set is $s_i=\{A,A,B,B,B\}$ and the corresponding message $m_i$ is ``ttvz''. Note that the alphabets in the message do not correspond to any symbol in natural language.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
           & 0A   & 1A   & 2A   & 3A   & 4A   & 5A   \\ \hline
        0B &      & txtt & txzt & xtzz & xzzz & xxvx \\ \hline
        1B & ttxt & ttxz & tzzz & ztzv & zzvz & vzxv \\ \hline
        2B & tttx & ttvz & tzhz & tvzv & zvhv & vvvz \\ \hline
        3B & tttv & ttvw & thzv & tvwv & hvzv & wvzv \\ \hline
        4B & ttht & thtw & thwz & hhvz & hwvv & wwvv \\ \hline
        5B & tthh & thhh & thww & hhwh & hwww & wwww \\ \hline
        \end{tabular}
    \caption{An emergent language in a Set-Reconstruct game.}
    \label{tab4.2:emregent_language_generation}
\end{table}

As we can see from Table \ref{tab4.2:emregent_language_generation}, there is no clear compositional structure in it. 

Based on the 2 properties of compositional languages illustrated in Section \ref{sec3.3:measurements}, we could see that the emergent language shown in Table \ref{tab4.2:emregent_language_generation} satisfies neither of mutual exclusivity nor orthogonality. To be specific, there is no common substrings of messages in every column/row, and some substrings, e.g. ``tt'' in column ``0A'', may be used in multiple columns/rows. Thus, the emergent language is not a perfectly compositional one as we expect.

However, as Set-Reconstruct game is a generation task, the agents may transmit more than numeric concepts in order that listeners could generate the original input. Thus, to verify whether this is the case, we illustrate an emergent language in a Set-Select game whose settings are exactly the same as the Set-Reconstruct game illustrated above, i.e. $|\mathcal{O}|=2, |N_o|=5, |M|=4, |V|=10$. The meanings and corresponding messages are shown in Table \ref{tab4.3:emregent_language_referential} given as follow.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
           & 0A   & 1A   & 2A   & 3A   & 4A   & 5A   \\ \hline
        0B &      & xxxv & xxvy & xvyy & vyxy & vyyy \\ \hline
        1B & xxxx & xxzx & xwxv & xvvv & vvxx & vvyy \\ \hline
        2B & xxyx & xqxx & xzxz & xwwv & vwvx & vvvv \\ \hline
        3B & xyxy & xqyx & xqqx & zxzz & wwwx & wvwv \\ \hline
        4B & yxyx & yxqy & qxqy & qzxq & zzxz & zwwz \\ \hline
        5B & yyxy & yyqy & qyyy & qqyy & zqqq & zzzz \\ \hline
        \end{tabular}
    \caption{An emergent language in a Set-Select game.}
    \label{tab4.3:emregent_language_referential}
\end{table}

Based on the message contents in Table \ref{tab4.3:emregent_language_referential}, we could find that the referential game does not make the emergent language perfectly compositional. 

According to \cite{kottur2017natural}, another alternative probability is that the message space is much larger in the previous game settings and thus it is over-complete for agents to encode the sets of objects in a compositional fashion. Thus, we re-train that agents with $|\mathcal{O}|=2, |N_o|=5, |M|=2, |V|=10$ \footnote{Here, the message space is still larger than meaning space, as we again do not want to make the success of agents depend on fine-tuning hyperparameters.} (where the size of meaning and message space are $25$ and $100$ respectively), and the emergent language is shown in Table \ref{tab4.4:emregent_language_referential2}. As we can see, the smaller message space does not necessarily facilitate the emergence of compositional language in Set-Select game.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
           & 0A & 1A & 2A & 3A & 4A & 5A \\ \hline
        0B &    & zv & vz & vv & vv & xv \\ \hline
        1B & zy & zu & zw & wz & wv & xw \\ \hline
        2B & yz & uu & zz & zt & ww & wx \\ \hline
        3B & yz & uy & uq & qz & tz & tw \\ \hline
        4B & yx & yy & ur & qq & qt & tt \\ \hline
        5B & xy & yr & ry & rx & xq & xt \\ \hline
        \end{tabular}
    \caption{Another emergent language in a Set-Select game.}
    \label{tab4.4:emregent_language_referential2}
\end{table}

\subsection{Topological Similarities}
\label{ssec4.2.2:topo_sim}

As introduced in subsection \ref{sec3.3:measurements}, we measure the topological similarity between meaning space and message space as a measure of compositionality. We list compositionality scores under different kinds of measurements in Table \ref{tab4.4:topo_sim_lans} given as follow.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
                          & Ham+Edit & Ham+BLEU & Euclid+Edit & Euclid+BLEU \\ \hline
        Compositional     & 1.00     & 0.61     & 0.38        & 0.24        \\ \hline
        Set-Reconstruct   & 0.32     & 0.27     & 0.60        & 0.65        \\ \hline
        Set-Select        & 0.13     & 0.16     & 0.45        & 0.52        \\ \hline
        Holistic          & -0.04    & -0.04    & 0.01        & 0.00        \\ \hline
    \end{tabular}
    \caption{Topological similarity scores of different languages.}
    \label{tab4.4:topo_sim_lans}
\end{table}

\noindent\textbf{Ham+Edit}: We first follow the distance measurements in \cite{brighton2006understanding}: i) use hamming distances between meaning sequences as the similarity measurement for meaning space; ii) use edit distances between corresponding messages as the similarity measurement for message space.

\noindent\textbf{Ham+BLEU}: In this setting, we use: i) hamming for meaning space too; ii) BLEU score illustrated in Section \ref{sec3.3:measurements} as the the similarity measurement for message space.

\noindent\textbf{Euclid+Edit}: In this setting, we use: i) Euclidean distance as the measurement for meaning space, e.g. Euclidean distance between ``4A2B'' and ``1A3B'' is \\ $\sqrt{(4-1)^2 + (2-3)^2}=\sqrt{10}$; ii) edit distance for message space.

\noindent\textbf{Euclid+BLEU}: In this setting, we use: i) Euclidean distance for meaning space; ii) BLEU score illustrated in Section \ref{sec3.3:measurements} for message space.

To get the upper bound and lower bound of compositionalities, we specifically designed: i) a perfectly compositional language, in which the message is exactly the same as meaning sequence, e.g. ``4A2B'' is represented as ``4829'' ($\mbox{A}\rightarrow 8, \mbox{B} \rightarrow 9$); ii) a holistic language, in which messages are randomly generated.

Then, from the above results, we could see that although the emergent languages in Set-Reconstruct and Set-Select games gain low topological similarity scores under Hamming distance for meaning space, they obtain much higher similarity scores under Euclidean distances for meaning space. Therefore, we argue that, although the emergent languages do not look like compositional, they can reflect the underlying structure of the meaning space. Based on the above results, we could also say that the meaning of symbols in the emergent language \textbf{is not numerals} defined in Subsection \ref{ssec3.1.2:numeral_in_game}. 

\subsection{Significance Test of Same Numeric Concepts}
\label{ssec4.2.3:significance_test}

Although the compositionality of emergent language is not like our natural language, we could also see that it reflects the underlying structure of meaning space. Thus, we further verify whether messages for meaning pairs that share same numeric concepts are more similar. To do this, we established 2 different datasets: i) meaning pairs sharing exactly same numeric concepts, e.g. ``4A3B'' and ``3A4B'', and corresponding BLEU similarity scores for their messages; ii) pairs of meaning sequences that share no numeric concept, e.g. ``4A3B'' and ``5A1B'', and corresponding BLEU similarity for their messages.

Then, we establish the following hypotheses for significance test:

\begin{itemize}
    \item \textbf{Null hypothesis}: The BLEU scores between messages are independent from whether meaning pairs share same numeric concepts.
    \item \textbf{Alternative hypothesis}: The BLEU scores between messages are \textbf{not} independent from whether meaning pairs share same numeric concepts.
\end{itemize}

The the $p$-values got on different languages are given in Table \ref{tab4.5:p-values} as follow.

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Language  & Compositional         & Set-Reconstruct          & Set-Select           & Holistic \\ \hline
    $p$-value & $1.93\times 10^{-69}$ & $7.01\times 10^{-3}$ & $2.87\times 10^{-3}$ & 0.57 \\ \hline
    \end{tabular}
    \caption{$p$-values of different languages.}
    \label{tab4.5:p-values}
\end{table}

The $p$-values for compositional language as well as emergent languages in both Set-Reconstruct and Set-Select games are smaller than $0.01$. Thus, it is safe to reject null hypothesis and accept the alternative hypothesis. That is, The BLEU scores between messages depend on whether their meaning pairs share same numeric concepts. To be more precise, the messages of meaning pairs share same numeric concepts have more unigrams and bi-grams in common.

\subsection{Generalisation of Emergent Language}
\label{ssec4.2.4:emergent_lan_generalise}

To verify whether the emergent language can be generalised to unseen sets, we train the randomly initialised listeners with several kinds of languages: i) compositional language; ii) an emergent language invented by other agents; iii) holistic language. And, the game settings are $|M|=8$, $|V|=10$, $|\mathcal{O}|=4$, $|N_{o}|=10$. Learning and performance curves of these languages on Set-Reconstruct and Set-Select games are given in  Figure \ref{fig4.0:listener_learning_generalise_gen} and Figure \ref{fig4.00:listener_learning_generalise_ref} respectively.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/listener_learning_generalise_gen.pdf}
    \caption{Learning and performance curves of different languages in Set-Reconstruct game.}
    \label{fig4.0:listener_learning_generalise_gen}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/listener_learning_generalise.pdf}
    \caption{Learning and performance curves of different languages in Set-Select game. Lines of ``emergent'' and ``emergent-forward'' overlap with each other.}
    \label{fig4.00:listener_learning_generalise_ref}
\end{figure}

It is quite suprising that, although we cannot see any significant pattern in the emergent language, it actually can be generalised to unseen sets of objects by listeners, as illustrated by the performance of listeners on evaluation dataset. Also, listener trained with emergent language converges faster on evaluation performance as well as training loss, although length of emergent messages ($|M|=8$) are longer than that of compositional language ($|M|=4$).

Besides, we also train listeners in Set-Reconstruct and Set-Select with languages emerged in the other game, i.e. ``emergent-select'' in Figure \ref{fig4.0:listener_learning_generalise_gen} and ``emergent-forward'' in Figure \ref{fig4.00:listener_learning_generalise_ref}. From the evaluation accuracy in Figure \ref{fig4.00:listener_learning_generalise_ref}, we could see that the emergent language in Set-Reconstruct game can be well generalised to unseen samples by listeners in Set-Select game. However, listeners in Set-Reconstruct game cannot generalise emergent language from Set-Select game, which is illustrated by the evaluation accuracies in Figure \ref{fig4.0:listener_learning_generalise_gen}. This phenomenon demonstrates that the information encoded by speakers in Set-Reconstruct games are richer than the information encoded by speakers in Set-Select games, or to say this demonstrates that speakers in Set-Reconstruct games may encode more than only numeric concepts.

Sum up from all above, although we cannot find observable patterns in emergent languages under various game settings, the emergent languages are actually easier for agents to learn and also can be generalised to unseen sets of objects. Thus, based on the previous topological similarity measurements and significance test, we claim that the emergent languages do capture the underlying structure of meaning space and encode them into sequences consisting of discrete variables.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Learning Speed \& Iterated Learning}
\label{sec4.3:learning_speed}

From the previous sections, we could see that the emergent languages can reflect the underlying structure of meaning spaces, although they may not be as compositional as our natural languages. Thus, we are further curious about the motivation of the emergent language. Or, to say, the reasons why computational agents prefer to communicate in such a ``non-natural''\footnote{From a human perspective, it is not like how we communicate numeric concepts through natural language.} way.

\subsection{For Listener}
\label{ssec4.3.1:learning_listener}

The first thing we are curious is whether the emergent language is the most easy one for listeners to understand. To verify this, we test the learning speeds of all kinds of languages with randomly initialised new listeners in both Set-Reconstruct game and Set-Select Game, and the results are shown in Figure \ref{fig4.1:listener_learning_generation} and Figure \ref{fig4.2:listener_learning_refer} respectively.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/listener_learning_generation.pdf}
    \caption{Learning and performance curves of different languages in Set-Reconstruct game.}
    \label{fig4.1:listener_learning_generation}
\end{figure}

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/listener_learning_refer.pdf}
    \caption{Learning and performance curves of different languages in Set-Select game.}
    \label{fig4.2:listener_learning_refer}
\end{figure}

From the above figures, we could easily see that emergent languages are learnt faster than compositional and holistic language in whichever the game, which implies that the emergent language has a lower sample complexity\cite{vapnik2013nature}.

\subsection{For Speaker}
\label{ssec4.3.2:learning_speaker}

We then test the learning speed of different languages on speaker, i.e. we randomly initialise new speakers and let it learn to produce messages of input sets under different languages. Note that the architecture of speaker is identical in Set2Seq2Seq and Set2Seq2Choice model, thus all the curves are shown in Figure \ref{fig4.3:speaker_learning} given as follow.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/speaker_learning.pdf}
    \caption{Speaker learning curves of different languages.}
    \label{fig4.3:speaker_learning}
\end{figure}

One thing we need to mention is that we also test an emergent language in Set-Select game with $|M|=2, |V|=10, |\mathcal{O}|=2, |N_o|=5$ which is denoted as ``emergent (len 2)''. Compared learning messages with length $2$ and $4$, we could easily see that smaller message spaces are always easier to learn than the larger ones.

Meanwhile, it is clear compositional languages are always easier for speaker to learn than the same sized emergent languages, which is contradictory to the situation on listener side. Our hypothesis is that compositional language is smoother function for speaker to learn and thus it is easier to be optimised. However, as time is limited, this phenomenon is not further discussed in this work but will be explored in the future works.

\subsection{Improvement by Iterated Learning}
\label{ssec4.3.:iterated_learning_improve}

Although the iterated learning framework \cite{kirby2002emergence} is proven to be effective in experiments with both Bayesian agents and humans, there are several obstacles for directly applying it into our neural agents:

\begin{enumerate}
    \item we cannot feed prior probability that favours high compositional languages to neural networks;
    \item the pre-training procedure in learning phase of original iterated learning need to be re-designed, as speakers and listeners in our game are not inverse functions to each other.
\end{enumerate}

Thus, we adapt iterated learning into our project, which is illustrated in Subsection \ref{ssec3.2.4:iterated_learning}, and train agent population with respect to normal training mechanism and iterated learning. The results are shown in Figure \ref{fig4.4:il_improve}. It needs to be pointed out that the distance measurement for meaning space is Euclidean distance for topological similarity, and measurement for message space is edit distance.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{graphs/il_improvement.pdf}
    \caption{Topological similarity curves of iterated learning and normal training in Set-Select game.}
    \label{fig4.4:il_improve}
\end{figure}

By comparing the curves of iterated learning and normal training, we can see a significant improvement of topological similarity in iterated learning, about $0.1$. However, although the messages emerged in iterate learning becomes more correlated with Euclidean distances between meanings, the numeric concepts in them are still not represented like numerals in natural languages.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Effects of Different Representations}
\label{sec4.4:represent_effect}

Compared our results in Section \ref{sec4.1:emergence} to \ref{sec4.3:learning_speed} with previous works in GLL, we argue that the different characteristics of emergents languages in our works are due to the feature representations of meanings.

To be specific, in our games, listeners need to generate object sequences or select the correct object sequence according to features representing each kind of objects. For example, the feature representation of set $\{A, B, A\}$ would be a sequence $\{[1 0], [0 1], [1 0]\}$ (assume that $|\mathcal{O}|=2, |N_o|=8$), and the corresponding message would be $\{2, 1\}=\{[0 0 1 0 0 0 0 0 0], [0 1 0 0 0 0 0 0 0]\}$ (assume that $|M|=|\mathcal{O}|=2, |V|=|N_o|=8$). Thus, to understand the message, the listener needs to correctly count the numbers of each kind of objects in the set and ground symbols to the counting results. During this procedure, there are 2 gaps between meanings (or perceptions) and messages: i) from meaning to numeric concepts; ii) from numeric concepts.

To verify which step imports bias towards emergent language, we slightly change the representation of sets in Set-Select game, i.e. we directly encode the numbers of each kind of objects as one-hot vectors and concatenate them to be the representation of the whole set. Take set $\{A, B, A\}$ as example, its representation would be \textbf{vector} $[0 0 1 0 0 0 0 0 0; 0 1 0 0 0 0 0 0 0]$, whereas its message is still the \textbf{sequence} \\ $\{[0 0 1 0 0 0 0 0 0], [0 1 0 0 0 0 0 0 0]\}$. Then, it is straightforward that mapping from messages to meanings is a linear transformation and thus it should be easy for neural networks to fit.

\begin{figure}[!h]
    \centering
    \subfigure[Listener learning speed]{
        \includegraphics[width=0.48\textwidth]{graphs/listener_learning_joshua.pdf}
    }
    \subfigure[Speaker learning speed]{
        \includegraphics[width=0.48\textwidth]{graphs/speaker_learning_joshua.pdf}
    }
    \caption{Learning speed of languages with different compositionalities with linear feature representations.}
    \label{fig4.5:learning_speed_joshua}
\end{figure}

First of all, we test the learning speed of manually designed languages with different topological similarity scores on both speaker and listener side, and the results are shown in Figure \ref{fig4.5:learning_speed_joshua}. Note that the measurement for meaning distance is Hamming distance and thus languages with higher $\rho$-values would ``look'' more like our natural language. As we can see in Figure \ref{fig4.5:learning_speed_joshua}, language with higher $\rho$-values are much more easier to learn for both speaker and listener, under the current scenario.

Then, we track the probabilities with different $\rho$-values during the iterated leaning procedure and the results are shown in Figure \ref{fig4.6:lan_prob_IL}. It is straightforward to see that high compositional languages gradually dominate among all kinds of languages generation by generation. 

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.6\textwidth]{graphs/language_probs_IL.pdf}
    \caption{Changes of probabilities of languages with different $\rho$-values during iterated learning.}
    \label{fig4.6:lan_prob_IL}
\end{figure}

To have an intuitive feeling about the final emergent language with iterated learning and current feature representations, we illustrate it in Table \ref{tab4.6:emregent_language_referential_perfect}. 

\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
        \hline
           & 0A & 1A & 2A & 3A & 4A & 5A & 6A & 7A & 8A \\ \hline
        0B &    & 20 & 60 & 30 & 30 & 10 & 50 & 70 & 00 \\ \hline
        1B & 42 & 22 & 62 & 82 & 32 & 12 & 52 & 72 & 02 \\ \hline
        2B & 48 & 28 & 68 & 88 & 38 & 18 & 58 & 78 & 08 \\ \hline
        3B & 47 & 27 & 67 & 87 & 37 & 17 & 57 & 77 & 07 \\ \hline
        4B & 46 & 26 & 66 & 86 & 36 & 16 & 56 & 76 & 06 \\ \hline
        5B & 45 & 25 & 65 & 85 & 35 & 15 & 55 & 75 & 05 \\ \hline
        6B & 41 & 21 & 61 & 85 & 31 & 11 & 51 & 71 & 01 \\ \hline
        7B & 44 & 24 & 64 & 84 & 34 & 14 & 54 & 74 & 04 \\ \hline
        8B & 33 & 23 & 63 & 83 & 33 & 13 & 53 & 73 & 03 \\ \hline
        \end{tabular}
    \caption{Final emergent language in linear feature representation and iterated learning.}
    \label{tab4.6:emregent_language_referential_perfect}
\end{table}

Then, it is straightforward to decipher the emergent language shown in Table \ref{tab4.6:emregent_language_referential_perfect}. Basically, the symbols appeared in the first digit represent the numbers of ``A'' and the symbols appeared in second digit represent the numbers of ``B''. Of course, the language is still not perfect compositional, as there are some repetitive messages for different meanings, such as ``3A5B'' (85) and ``3A6B'' (85). Besides, it worth mentioning that the same symbol still represents different meanings if it appears at different positions.

Overall, we could say the the obstacle for the emergence of compositional languages in our Set-Reconstruct and Set-Select games is that symbols in messages do not directly correspond to any feature in the original meaning spaces. As long as the features we want the emergent language to represent is established, the agents could invent almost perfect compositional language by iterated learning.

\section{Further Discussion}
\label{sec4.5:discuss}

Comparing the experimental results in this chapter with previous work in GLL, e.g. \cite{kottur2017natural, hermann2017grounded, havrylov2017emergence, mordatch2018emergence}, we propose an alternative hypothesis to explain the emergence of compositional language (some previous works call it natural language) during the autonomous communication among agents population.

First of all, we argue that the feature vectors of input experience and perceptions should be inherently disentangled, i.e. the feature vectors of these inputs should satisfy mutual exclusivity and orthogonality defined in Subsection \ref{ssec4.2.1:emergent_languages}, in order to facilitate the emergence of compositional language. Then, it could be an optimal method to use a single symbol as a feature representation of a disentangled element in feature vectors. By comparing the emergent languages in Section \ref{sec4.1:emergence} to \ref{sec4.3:learning_speed} with that in Section \ref{sec4.4:represent_effect}, it is straightforward to see that linear transformed feature representations would be much more optimal for the emergence of highly compositional languages. However, as lots of previous use images as the perceptions for speakers, there is still a gap between our 2 representing methods. Without further experiment, we are not sure about whether the emergence of compositional languages of those works are caused by that convolutional neural networks (CNN) can spontaneously encode images into independent features.

Secondly, we argue that iterated learning is an effective method to introduce inductive bias into multi-agent autonomous communication systems, and thus improve the compositionalities of emergent languages. Considering the discoveries in \cite{locatello2018challenging}, we claim that the compositional languages are highly correlated with the appearance of disentangled representations. Further, inductive bias towards compositionalities of different kinds of symbols (which correspond to words in natural languages) should be introduced to different spaces. For example, inductive bias towards the compositionality of symbols corresponding to objects/attributes that physically exists in real/virtual world can be introduced by iterated learning, as the feature values of these objects/attributes are mutually exclusive and independent (or to say, they are inherently disentangled). On the other hand, compositionality of function words, such as numerals in our project, requires the agents to first encode the input features in some specific ways and obtain disentangled representations. Thus, without specially designed training mechanism or data samples that could introduce such pressure, it is natural for agents to invent effective but non-natural ``languages'' during their autonomous communication.